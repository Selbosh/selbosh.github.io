---
title: Advent of Code 2021
date: '2021-12-01T09:00:00+00:00'
slug: advent-2021
categories: ['R']
images: ['/img/2020/adventofcode.jpg']
---

It's that time of year again.
And not just for [Secret Santa](/2016/12/07/santa/)---it's time for the [Advent of Code](https://adventofcode.com/), a series of programming
puzzles in the lead-up to Christmas.

I'm doing the 2021 challenge in R---in the form of an open-source [R package](https://github.com/Selbosh/adventofcode2021), to demonstrate a [test-driven](https://personalpages.manchester.ac.uk/staff/david.selby/rthritis/2021-11-19-unittesting/) workflow.

<div style="text-align:center;">
  <div class="github-card" data-github="Selbosh/adventofcode2021" data-width="400" data-height="" data-theme="default" style="display:block; margin:0 auto;"></div>
</div>
<script src="//cdn.jsdelivr.net/github-cards/latest/widget.js"></script>

Each puzzle description typically comes with a few simple examples of inputs and outputs.
We can use these to define expectations for unit tests with the [**testthat**](https://testthat.r-lib.org/) package.
Once a function passes the unit tests, it should be ready to try with the main puzzle input.

Check my [**adventofcode2021**](https://github.com/Selbosh/adventofcode2021) repository on GitHub for the latest.

```r
remotes::install_github('Selbosh/adventofcode2021')
```

1. [Sonar Sweep](#day1)
2. [Dive!](#day2)
3. [Binary Diagnostic](#day3)
4. [Giant Squid](#day4)
5. [Hydrothermal Venture](#day5)

## Day 1 - [Sonar Sweep](https://adventofcode.com/2021/day/1) {#day1}

### Increases

To count the number of times elements are increasing in a vector it's as simple as

```{r}
depths <- c(199, 200, 208, 210, 200, 207, 240, 269, 260, 263)
sum(diff(depths) > 0)
```

for which I defined a function called [`increases`](https://github.com/Selbosh/adventofcode2021/blob/main/R/day01.R#L91-L93).

### Rolling sum

For part two, we first want to calculate the three-depth moving sum, then we count the increases as in part one.
There are plenty of solutions in external R packages for getting lagged (and leading) vectors, for instance `dplyr::lag()` and `dplyr::lead()`: 

```{r, message = FALSE}
depths + dplyr::lead(depths) + dplyr::lead(depths, 2)
```

Or you could even calculate the rolling sum using a pre-made solution in **zoo** (Z's Ordered Observations, a time-series analysis package).

```{r}
zoo::rollsum(depths, 3)
```

To avoid loading any external packages at this stage, I defined my own base R function called [`rolling_sum()`](https://github.com/Selbosh/adventofcode2021/blob/main/R/day01.R#L99-L101), which uses `tail` and `head` with negative lengths to omit the first and last elements of the vector:

```{r}
head(depths, -2) + head(tail(depths, -1), -1) + tail(depths, -2)
```

As [David Schoch points out](https://twitter.com/schochastics/status/1466062839077027845), you can just use the `lag` argument of `diff` to make this entire puzzle into a one-liner:

```{r}
sapply(c(1, 3), \(lag) sum(diff(depths, lag) > 0))
```

## Day 2 - [Dive!](https://adventofcode.com/2021/day/2) {#day2}

### Depth sum

Read in the input as a two-column data frame using `read.table()`.
I gave mine nice column names, `cmd` and `value`, but this isn't essential.

Then take advantage of the fact that `TRUE == 1` and `FALSE == 0` to make a mathematical `ifelse`-type statement for the horizontal and vertical movements.
In my R package, this is implemented as a function called [`dive()`](https://github.com/Selbosh/adventofcode2021/blob/main/R/day02.R#L70-L76):

```r
x <- (cmd == 'forward') * value
y <- ((cmd == 'down') - (cmd == 'up')) * value
sum(x) * sum(y)
```

### Cumulative depth sum

Part two is much like part one, but now `y` represents (change in) aim, and (change in) depth is derived from that.
Don't forget the function `cumsum()`, which can save you writing a loop!
Here is the body of my function [`dive2()`](https://github.com/Selbosh/adventofcode2021/blob/main/R/day02.R#L80-L87):

```r
x <- (cmd == 'forward') * value
y <- ((cmd == 'down') - (cmd == 'up')) * value
depth <- cumsum(y) * x
sum(x) * sum(depth)
```

## Day 3 - [Binary Diagnostic](https://adventofcode.com/2021/day/2) {#day3}

### Power consumption

There are a few different ways you could approach part one, but my approach was first to read in the data as a data frame of binary integers using the function `read.fwf()`.
Then, find the most common value in each column using the base function `colMeans()` and rounding the result.

According to the instructions, in the event of a tie you should take 1 to be the most common digit.
Although this is familiar to real life---0.5 rounds up to 1---computers [don't work this way](https://en.wikipedia.org/wiki/Rounding#Round_half_to_even): R rounds to even instead (see `?round`).
Because zero is even, that means `round(0.5)` yields 0.
To get around this, add 1 before rounding, then subtract it again.

My function [`power_consumption()`](https://github.com/Selbosh/adventofcode2021/blob/main/R/day03.R#L78-L81), which once again takes advantage of `TRUE` being equivalent to 1 and `FALSE` to 0:

```r
common <- round(colMeans(x) + 1) - 1
binary_to_int(common) * binary_to_int(!common)
```

To convert a vector of binary digits to decimal, I use the following [utility function](https://github.com/Selbosh/adventofcode2021/blob/main/R/day03.R#L104-L106):

```r
binary_to_int <- function(x) {
  sum(x * 2 ^ rev(seq_along(x) - 1))
}
```

However, if using a string representation then there's a handy function in base R called `strtoi()` that you could also use for this ([thanks to Riinu Pius for that tip](https://twitter.com/_Riinu_/status/1466681283887648769)).

### Life support

Part two finds the common digits in a successively decreasing set of binary numbers.
A loop is appropriate here, since we can halt once there is only one number left.
As this loop will only run (at most) 12 times in total, it shouldn't be too slow in R.

Function [`life_support()`](https://github.com/Selbosh/adventofcode2021/blob/main/R/day03.R#L85-L98):

```r
life_support <- function(x) {
  oxygen <- co2 <- x
  for (j in 1:ncol(x)) {
    if (nrow(oxygen) > 1) {
      common <- most_common(oxygen)
      oxygen <- oxygen[oxygen[, j] == common[j], ]
    }
    if (nrow(co2) > 1) {
      common <- most_common(co2)
      co2 <- co2[co2[, j] != common[j], ]
    }
  }
  binary_to_int(oxygen) * binary_to_int(co2)
}
```

There might be cleverer ways of doing this.

## Day 4 - [Giant Squid](https://adventofcode.com/2021/day/4) {#day4}

### Bingo

This is one of those problems where half the battle is working out which data structure to use.
I wrote a function [`read_draws()`](https://github.com/Selbosh/adventofcode2021/blob/main/R/day04.R#L80-L84) that reads in the first line of the file to get the drawn numbers, then separately reads in the remainder of the file to get the bingo cards stacked as a data frame.
Later we take advantage of the fact that the bingo cards are square to split the data frame into a list of matrices.

```r
read_draws <- function(file) {
  draws <- scan(file, sep = ',', nlines = 1, quiet = TRUE)
  cards <- read.table(file, skip = 1)
  list(draws = draws, cards = cards)
}
```

As numbers are called out, I replace them in the dataset with `NA`s.
Then the helper [`score_card()`](https://github.com/Selbosh/adventofcode2021/blob/main/R/day04.R#L86-L91) counts the number of `NA`s in each row and column.
If there are not enough, we return zero, else we calculate the score.

```r
score_card <- function(mat, draw) {
  marked <- is.na(mat)
  if (all(c(rowMeans(marked), colMeans(marked)) != 1))
    return(0)
  sum(mat, na.rm = TRUE) * draw
}
```

Then we put it all together, looping through the draws, replacing numbers with `NA` and halting as soon as someone wins.
Function [`play_bingo()`](https://github.com/Selbosh/adventofcode2021/blob/main/R/day04.R#L98-L111) is defined as follows, using just base R commands:

```r
play_bingo <- function(draws, cards) {
  size <- ncol(cards)
  ncards <- nrow(cards) / size
  ids <- rep(1:ncards, each = size)

  for (d in draws) {
    cards[cards == d] <- NA
    score <- sapply(split(cards, ids), score_card, draw = d)
    if (any(score > 0))
      return(score[score > 0])
  }
}
```

### Last caller

Part two is very similar, but we throw away each winning bingo card as we go to avoid redundant computation, eventually returning the score when there is only one left.
Here is function [`play_bingo2()`](https://github.com/Selbosh/adventofcode2021/blob/main/R/day04.R#L115-L131), which uses the same two utility functions:

```r
play_bingo2 <- function(draws, cards) {
  size <- ncol(cards)

  for (d in draws) {
    ncards <- nrow(cards) / size
    ids <- rep(1:ncards, each = size)
    cards[cards == d] <- NA
    score <- sapply(split(cards, ids), score_card, draw = d)
    if (any(score > 0)) {
      if (ncards == 1)
        return(score[score > 0])
      cards <- cards[ids %in% which(score == 0), ]
    }
  }
}
```

Further optimizations are possible.
For example: as written, we calculate every intermediate winner's score, but we only really need to do it for the first (part 1) and last (part 2) winners.

Also, we could draw more than one number at a time, as we know that nobody's going to win until at least the fifth draw (for 5&times;5 cards) and from there, increment according to the minimum number of unmarked numbers on any row or column.

I didn't bother implementing either of these, as it already runs quickly enough.

## Day 5 - [Hydrothermal Venture](https://adventofcode.com/2021/day/5) {#day5}

For a while I tried to think about clever mathematical ways to solve the system of inequalities, but this gets complicated when working on a grid, and where some segments are collinear.
In the end it worked out quicker to what seems like a 'brute force' approach:
generate all the points on the line segments and then simply count how many times they appear.

This is a problem that really lends itself to use of **tidyr** functions like `separate()` and `unnest()`, so naturally I made life harder for myself by doing it in base R, instead.

First, read in the coordinates as a data frame with four columns, `x1`, `y1`, `x2` and `y2`.
The _nice_ way to do this is with `tidyr::separate()` but `strsplit()` works just fine too.
Here is my parsing function, [read_segments()](https://github.com/Selbosh/adventofcode2021/blob/main/R/day05.R#L77-L82):

```r
read_segments <- function(x) {
  lines <- do.call(rbind, strsplit(readLines(x), '( -> |,)'))
  storage.mode(lines) <- 'numeric'
  colnames(lines) <- c('x1', 'y1', 'x2', 'y2')
  as.data.frame(lines)
}
```

This is one of the few puzzles where the solution to part two is essentially contained in part one.
Depending on how you implement your home-rolled `unnest`-like function, it could just be a case of filtering out the diagonal lines in part one.
I make liberal use of `mapply` for looping over two vectors at once.

In the penultimate line, we take advantage of vector broadcasting, which handles all the horizontal and vertical lines where you have multiple coordinates on one axis paired with a single coordinate on the other.
For the diagonal lines, there is a 1:1 relationship so the coordinates just bind together in pairs.
Finally, we work out how to count the rows, without using `dplyr::count`.
If you convert to a data frame, then `table()` does this for you.

```r
count_intersections <- function(lines, part2 = FALSE) {
  if (!part2)
    lines <- subset(lines, x1 == x2 | y1 == y2)
  x <- mapply(seq, lines$x1, lines$x2)
  y <- mapply(seq, lines$y1, lines$y2)
  xy <- do.call(rbind, mapply(cbind, x, y))
  sum(table(as.data.frame(xy)) > 1)
}
```

I'm fairly pleased to get the main solution down to [essentially four lines of code](https://github.com/Selbosh/adventofcode2021/blob/main/R/day05.R#L89-L96), though I'm certain that there are more computationally efficient ways of tackling this problem---if you value computer time more than your own time.

For the tidyverse approach, see [David Robinson's solution](https://twitter.com/drob/status/1467361848525787138).
