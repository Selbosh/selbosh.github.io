---
title: The unequalled joy of non-equi joins
date: '2021-02-13T16:00:00+00:00'
slug: 'joins'
categories: ['R']
images: ['/img/2021/joins.png']
---

```{r setup, include=FALSE}
library(knitr)
opts_chunk$set(echo = TRUE, message = FALSE, warning = FALSE)
set.seed(1)
options(digits = 3)
knit_print.data.frame <- function(x, ...) {
  res = paste(c('', kable(x), ''), collapse = '\n')
  asis_output(res)
}
registerS3method('knit_print', 'data.frame', knit_print.data.frame)
registerS3method('knit_print', 'grouped_df', knit_print.data.frame)
```

A common task in data analysis is to _merge_ or _join_ two tables according to shared _keys_ or values.
The operation is perhaps most commonly associated with relational databases and structured query language ([SQL](https://en.wikipedia.org/wiki/SQL)) but it's just as useful in R with data frames.

Most joins are _equi-joins_, matching rows according to two columns having exactly equal values.
These are easy to perfom in R using the base `merge()` function, the various `join()` functions in **dplyr** and the `X[i]` syntax of **data.table**.

But sometimes we need _non-equi joins_ or [\(\theta\)-joins](https://en.wikipedia.org/wiki/Relational_algebra#Joins_and_join-like_operators), where the matching condition is an interval or a set of inequalities.
Other situations call for a _rolling join_, used to link records according to their proximity in a time sequence.

How do you perform non-equi joins and rolling joins in R?

### Motivating example

A famous YouTuber is testing out a new marketing strategy, promoting specific videos on social media.
They collect daily view counts of old videos and want to summarise these counts in the days following each promotion.

The tables `promos` and `views` are as follows.
The data span a two-week period, but for certain days and certain videos, the view counts are missing.

```{r youtube, echo=FALSE}
set.seed(42)
library(tidyverse)
promos <- tibble(
  video = c('A', 'A', 'B', 'B', 'C'),
  promo_date = as.Date(c('2020-04-01', '2020-04-07',
                         '2020-04-03', '2020-04-08',
                         '2020-04-03'))
)
views <- expand_grid(
  video = LETTERS[1:3],
  view_date = seq(as.Date('2020-04-01'), length = 14, by = 1)
) %>% mutate(views = rexp(n(), 1/5000)) %>%
  filter(runif(n()) < .8)
knitr::kable(promos)
knitr::kable(views)
```
What are the mean view counts on videos in the three days immediately following promotions for those videos?

I will show how you might accomplish this task using either non-equi joins or rolling joins in R.

### Crossing + filter with dplyr

The package **dplyr** has no function for joining on anything other than an equality relation.
However, you can get the same results (possibly less efficiently) using an outer join or Cartesian product, followed by a filtering operation.

```{r}
library(dplyr)
views %>%
  # Crossing
  full_join(promos) %>%
  # Filter
  filter(view_date >= promo_date,
         view_date <= promo_date + 3) %>%
  # Aggregate
  group_by(video) %>%
  summarise(mean(views), sd(views), `n days` = n())
```
It would also be possible to compare promoted days with non-promoted days for each video, either by creating a binary indicator (instead of a filter) or by rejoining the table with the original dataset after the filter step.

### Non-equi joins with sqldf

The **sqldf** package lets you query R data frames with SQL, as if you were working with a relational database.
The result of the query is another data frame, and performance is sometimes better than equivalent R functions.

```{r}
library(sqldf)
sqldf('SELECT v.video, view_date, views
       FROM views v
       JOIN promos p
       ON v.video = p.video AND
          view_date BETWEEN promo_date AND promo_date + 3'
      ) %>%
  group_by(video) %>%
  summarise(mean(views), sd(views), `n days` = n())
```
The aggregation step could also be written in SQL, but it makes sense only to use SQL where it is absolutely needed, and to use native R functions for everything else.

Having access to this functionality is very powerful, but has the obvious disadvantage that you need to learn a bit of SQL to understand the syntax.

### Non-equi joins with data.table

The high-performance data manipulation package **data.table** now (as of [v1.9.8](https://github.com/Rdatatable/data.table/blob/master/NEWS.0.md#new-features)) supports non-equi joins.

Non-equi joins are made possible with the `X[i]` merging syntax and the `on` argument.
It's slightly less flexible than the equivalent SQL, because you can't just write `promo_date + 3` in the inequality: instead it needs to be an explicit column in the table.
You also can't use the infix `%between%` operator, so two inequalities have to do instead.
Otherwise the syntax is similar.
Like in SQL, a prefix is used to disambiguate the column names: [here it's `x.name`](https://stackoverflow.com/a/44343424).

```{r}
library(data.table)
setDT(views)
setDT(promos)[, promo_end := promo_date + 3]
views[promos,
      .(video, views, x.view_date),
      # Non equi join:
      on = .(video,
             view_date >= promo_date,
             view_date <= promo_end)
      ][, # Chain into aggregate:
        .(mean = mean(views), sd = sd(views), .N),
        by = video]
```

### Rolling joins with data.table

This particular example, since it involves a time variable, is even simpler using a _rolling join_.
The concept is a bit confusing, but essentially it attributes records in one table with the most recent preceding records in the second table.
You can read more about rolling joins in [this blog post by Robert Norberg](https://www.r-bloggers.com/2016/06/understanding-data-table-rolling-joins/).

When performing rolling joins in **data.table**, one of the joining time columns gets dropped, which can make it hard to identify your records if they don't have an explicit ID.
To mitigate this, we will copy each date column to the name `join_date` and join on that.

```{r, echo = -1, results='hide'}
promos[, promo_end := NULL]
views[, join_date := view_date]
promos[, join_date := promo_date]

setkey(views, video, join_date)
setkey(promos, video, join_date)
```
```{r}
promos[views, roll = TRUE]
```

The syntax `promos[views, roll=TRUE]` means "which promotion immediately preceded each viewing date?"
Conversely, `views[promos, roll=TRUE]` means "which viewing dates immediately preceded each promotion?"

In this case, we want something _close_ to the former, but we're only interested in promos in the past 3 days, whereas by default it'll extend back into the depths of time looking for the last one, regardless of how long ago.

By changing `roll = TRUE` to `roll = 3` the join will fail to match when the `join_date` differs by more than three days between the two tables.
If we wanted to go in the opposite direction in time, we could use `roll = -Inf` to search forwards in time for future promotions, and `roll = -3` for only those in the following three days.

```{r}
promos[views, roll = 3]
```

Since the default in **data.table**'s `X[i]` merge syntax is `nomatch = NA`, we get all of the `views` back, with the column `promo_date` equal to the date of the last promotion (in the last three days), or `NA` if no such promotion was found.
If we set `nomatch = 0` then these non-matching values are dropped from the result.

So the full operation to calculate the summary figures is
```{r}
promos[views, roll = 3, nomatch = 0
       ][j = .(mean = mean(views), sd = sd(views), .N),
         by = video]
```

If the intervals needed to be different lengths for each of the campaigns (i.e. not all equal to 3), then you would probably want a non-equi join rather than a rolling join in this case.

### Extensions

Arguably, for these examples you'd want to compare the view counts in promotional periods with those outside promotional periods.
This does not require a special kind of join; rather you perform the non-equi or rolling join as above and then wrangle the output accordingly.

If the non-matching rows are filtered out, you need to re-join with the original dataset.
Otherwise, you need to use some sort of indicator variable for whether the viewing date falls within a promotional period or not.

```{r, echo = FALSE}
setDF(promos[, join_date := NULL])
setDF(views[, join_date := NULL])
```

In **dplyr**:

```{r}
promos %>%
  full_join(views) %>%
  mutate(promo = between(view_date - promo_date, 0, 3)) %>%
  group_by(video, view_date) %>%
  summarise(promo = any(promo),
            views = unique(views)) %>%
  group_by(promo) %>%
  summarise(mean(views), sd(views), n = n())
```
In **data.table**:

```{r, echo=FALSE, results='hide'}
setDT(promos)[, join_date := promo_date]
setDT(views)[, join_date := view_date]

setkey(views, video, join_date)
setkey(promos, video, join_date)
```

```{r}
promos[views, roll = 3][
         j = .(mean = mean(views), sd = sd(views), .N),
         by = .(promo = !is.na(promo_date))]
```
